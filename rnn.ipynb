{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncated backpropagation\n",
    "def detach(states):\n",
    "    return [state.detach() for state in states] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 20\n",
    "epochs = 50\n",
    "seqlen = 30\n",
    "\n",
    "zsize = 32\n",
    "nhidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1500, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.from_numpy(np.load('z.npy'))\n",
    "z = z.view(bsz, -1, z.size(1)).to(device)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V(\n",
       "  (lstm): LSTM(32, 256, batch_first=True)\n",
       "  (linear): Linear(in_features=256, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class V(nn.Module):\n",
    "    def __init__(self, nembed, nhidden=265, nlayers=1):\n",
    "        super(V, self).__init__()\n",
    "\n",
    "        self.nhidden = nhidden\n",
    "        self.nlayers = nlayers\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        self.lstm = nn.LSTM(nembed, nhidden, nlayers, batch_first=True)\n",
    "        self.linear = nn.Linear(nhidden, nembed)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        # Forward propagate LSTM\n",
    "        out, (h, c) = self.lstm(x, h)\n",
    "        out = self.linear(out)\n",
    "        return out, (h, c)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.nlayers, bsz, self.nhidden).to(device),\n",
    "                torch.zeros(self.nlayers, bsz, self.nhidden).to(device))\n",
    "\n",
    "\n",
    "model = V(zsize, nhidden).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.2224\n",
      "Epoch [11/50], Loss: 0.0331\n",
      "Epoch [21/50], Loss: 0.0253\n",
      "Epoch [31/50], Loss: 0.0218\n",
      "Epoch [41/50], Loss: 0.0201\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    # Set initial hidden and cell states\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    for i in range(0, z.size(1) - seqlen, seqlen):\n",
    "        # Get mini-batch inputs and targets\n",
    "        inputs = z[:, i:i+seqlen, :]\n",
    "        targets = z[:, (i+1):(i+1)+seqlen, :]\n",
    "        \n",
    "        # Forward pass\n",
    "        hidden = detach(hidden)\n",
    "        outputs, hidden = model(inputs, hidden)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'\n",
    "               .format(epoch+1, epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.init_hidden()\n",
    "z1 = model(z, hidden)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78542835, 0.42561463, 0.67908615, 0.9246513 , 0.73405993,\n",
       "       0.9516081 , 0.8526774 , 0.72184086, 0.88601476, 0.8110216 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.linalg.norm(z[0, 0, :].cpu().data - z1[0, :, :].cpu().data, axis=1)\n",
    "# np.linalg.norm(inputs.cpu().data - targets.cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
